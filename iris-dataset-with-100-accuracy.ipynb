{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:29:44.242634Z","iopub.execute_input":"2025-06-10T13:29:44.242862Z","iopub.status.idle":"2025-06-10T13:29:46.879725Z","shell.execute_reply.started":"2025-06-10T13:29:44.242838Z","shell.execute_reply":"2025-06-10T13:29:46.878807Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.datasets import load_iris\n\ndata=load_iris()\n\ndir(data)\nX=data.data\ny=data.target\nX,y\n\nX.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:32:40.850944Z","iopub.execute_input":"2025-06-10T13:32:40.851594Z","iopub.status.idle":"2025-06-10T13:32:40.858962Z","shell.execute_reply.started":"2025-06-10T13:32:40.851569Z","shell.execute_reply":"2025-06-10T13:32:40.858325Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(150, 4)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"class LoadIrisv0(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1=nn.Linear(in_features=4,out_features=10)\n        self.layer2=nn.Linear(in_features=10,out_features=20)\n        self.layer3=nn.Linear(in_features=20,out_features=3)\n        self.relu=nn.ReLU()\n    def forward(self,x):\n        x=self.relu(self.layer1(x))\n        x=self.relu(self.layer2(x))\n        x=self.layer3(x)\n        \n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:43:33.251308Z","iopub.execute_input":"2025-06-10T13:43:33.252149Z","iopub.status.idle":"2025-06-10T13:43:33.257571Z","shell.execute_reply.started":"2025-06-10T13:43:33.252121Z","shell.execute_reply":"2025-06-10T13:43:33.256592Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"model_0=LoadIrisv0()\nmodel_0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:43:35.835018Z","iopub.execute_input":"2025-06-10T13:43:35.835582Z","iopub.status.idle":"2025-06-10T13:43:35.841931Z","shell.execute_reply.started":"2025-06-10T13:43:35.835556Z","shell.execute_reply":"2025-06-10T13:43:35.841199Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"LoadIrisv0(\n  (layer1): Linear(in_features=4, out_features=10, bias=True)\n  (layer2): Linear(in_features=10, out_features=20, bias=True)\n  (layer3): Linear(in_features=20, out_features=3, bias=True)\n  (relu): ReLU()\n)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:41:11.164669Z","iopub.execute_input":"2025-06-10T13:41:11.165179Z","iopub.status.idle":"2025-06-10T13:41:11.168875Z","shell.execute_reply.started":"2025-06-10T13:41:11.165157Z","shell.execute_reply":"2025-06-10T13:41:11.168108Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch \nfrom torch import nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:32:06.722781Z","iopub.execute_input":"2025-06-10T13:32:06.723060Z","iopub.status.idle":"2025-06-10T13:32:12.395506Z","shell.execute_reply.started":"2025-06-10T13:32:06.723043Z","shell.execute_reply":"2025-06-10T13:32:12.394744Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data.feature_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:44:13.626884Z","iopub.execute_input":"2025-06-10T13:44:13.627165Z","iopub.status.idle":"2025-06-10T13:44:13.632275Z","shell.execute_reply.started":"2025-06-10T13:44:13.627146Z","shell.execute_reply":"2025-06-10T13:44:13.631645Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"['sepal length (cm)',\n 'sepal width (cm)',\n 'petal length (cm)',\n 'petal width (cm)']"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:45:45.843979Z","iopub.execute_input":"2025-06-10T13:45:45.844273Z","iopub.status.idle":"2025-06-10T13:45:46.017083Z","shell.execute_reply.started":"2025-06-10T13:45:45.844251Z","shell.execute_reply":"2025-06-10T13:45:46.016267Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"X_train=torch.tensor(X_train,dtype=torch.float32)\nX_test=torch.tensor(X_test,dtype=torch.float32)\ny_train=torch.tensor(y_train,dtype=torch.float32)\ny_train=torch.tensor(y_train,dtype=torch.float32)\n\nres=model_0(X_train)\nres.shape\nres\n\ny_logits=res\ny_pred=torch.argmax(torch.softmax(y_logits,dim=1),dim=1)\ny_pred.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T14:13:32.500006Z","iopub.execute_input":"2025-06-10T14:13:32.500308Z","iopub.status.idle":"2025-06-10T14:13:32.509352Z","shell.execute_reply.started":"2025-06-10T14:13:32.500285Z","shell.execute_reply":"2025-06-10T14:13:32.508575Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1802264216.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  X_train=torch.tensor(X_train,dtype=torch.float32)\n/tmp/ipykernel_35/1802264216.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  X_test=torch.tensor(X_test,dtype=torch.float32)\n/tmp/ipykernel_35/1802264216.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y_train=torch.tensor(y_train,dtype=torch.long)\n/tmp/ipykernel_35/1802264216.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y_train=torch.tensor(y_train,dtype=torch.long)\n","output_type":"stream"},{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"torch.Size([120])"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"loss=nn.CrossEntropyLoss()\n\noptimizer=torch.optim.Adam(params=model_0.parameters(),lr=0.01)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:52:22.969080Z","iopub.execute_input":"2025-06-10T13:52:22.969767Z","iopub.status.idle":"2025-06-10T13:52:26.701379Z","shell.execute_reply.started":"2025-06-10T13:52:22.969741Z","shell.execute_reply":"2025-06-10T13:52:26.700658Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs=100\n\nfor epoch in range(epochs):\n    model_0.train()\n    y_logits=model_0(X_train)\n    loss_train=loss_fn(y_logits,y_train)\n    # y_pred=torch.softmax(y_logits, dim=1)\n    y_pred=torch.argmax(y_logits, dim=1)\n    \n    acc1=accuracy_fn(y_pred,y_train)\n    optimizer.zero_grad()\n    loss_train.backward()\n    optimizer.step()\n    model_0.eval()\n    \n    with torch.inference_mode():\n        y_logits=model_0(X_test)\n        loss_test=loss_fn(y_logits,y_test)\n        # y_pred=torch.softmax(y_logits, dim=1)\n        y_pred=torch.argmax(y_logits, dim=1)\n        \n        acc2=accuracy_fn(y_pred,y_test)\n        \n    if (epoch+1) % 10 == 0:\n        print(f\"Epoch {epoch+1}/{epochs}|\"\n              f\"Train loss:{loss_train:.4f}| Train acc: {acc1:.2f}% | \"\n              f\"Test loss:{loss_test:.4f}| Test acc: {acc2:.2f}%\")\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T14:30:08.849835Z","iopub.execute_input":"2025-06-10T14:30:08.850130Z","iopub.status.idle":"2025-06-10T14:30:08.998045Z","shell.execute_reply.started":"2025-06-10T14:30:08.850109Z","shell.execute_reply":"2025-06-10T14:30:08.997195Z"}},"outputs":[{"name":"stdout","text":"Epoch 10/100|Train loss:0.0480| Train acc: 98.33% | Test loss:0.0230| Test acc: 100.00%\nEpoch 20/100|Train loss:0.0479| Train acc: 98.33% | Test loss:0.0224| Test acc: 100.00%\nEpoch 30/100|Train loss:0.0478| Train acc: 98.33% | Test loss:0.0218| Test acc: 100.00%\nEpoch 40/100|Train loss:0.0477| Train acc: 98.33% | Test loss:0.0218| Test acc: 100.00%\nEpoch 50/100|Train loss:0.0476| Train acc: 98.33% | Test loss:0.0215| Test acc: 100.00%\nEpoch 60/100|Train loss:0.0475| Train acc: 98.33% | Test loss:0.0215| Test acc: 100.00%\nEpoch 70/100|Train loss:0.0481| Train acc: 98.33% | Test loss:0.0238| Test acc: 100.00%\nEpoch 80/100|Train loss:0.0486| Train acc: 98.33% | Test loss:0.0200| Test acc: 100.00%\nEpoch 90/100|Train loss:0.0477| Train acc: 98.33% | Test loss:0.0198| Test acc: 100.00%\nEpoch 100/100|Train loss:0.0474| Train acc: 98.33% | Test loss:0.0198| Test acc: 100.00%\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"def accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n    acc = (correct / len(y_pred)) * 100 \n    return acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T14:01:54.501302Z","iopub.execute_input":"2025-06-10T14:01:54.502226Z","iopub.status.idle":"2025-06-10T14:01:54.506259Z","shell.execute_reply.started":"2025-06-10T14:01:54.502195Z","shell.execute_reply":"2025-06-10T14:01:54.505502Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Ensure all tensors have correct types\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)  # Targets must be long integers\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# Training loop\nepochs = 100\n\nfor epoch in range(epochs):\n    # Training phase\n    model_0.train()\n    \n    # 1. Forward pass\n    train_logits = model_0(X_train)\n    \n    # 2. Calculate loss (using raw logits)\n    train_loss = loss_fn(train_logits, y_train)  # CrossEntropyLoss wants logits\n    \n    # 3. Calculate accuracy\n    train_pred = torch.argmax(train_logits, dim=1)  # Convert to class predictions\n    train_acc = accuracy_fn(y_train, train_pred)\n    \n    # 4. Backpropagation\n    optimizer.zero_grad()\n    train_loss.backward()\n    optimizer.step()\n    \n    # Evaluation phase\n    model_0.eval()\n    with torch.inference_mode():\n        # 1. Forward pass\n        test_logits = model_0(X_test)\n        \n        # 2. Calculate test loss\n        test_loss = loss_fn(test_logits, y_test)\n        \n        # 3. Calculate test accuracy\n        test_pred = torch.argmax(test_logits, dim=1)\n        test_acc = accuracy_fn(y_test, test_pred)\n    \n    # Print progress\n    if (epoch+1) % 10 == 0:\n        print(f\"Epoch {epoch+1}/{epochs} | \"\n              f\"Train Loss: {train_loss.item():.4f} | Train Acc: {train_acc:.2f}% | \"\n              f\"Test Loss: {test_loss.item():.4f} | Test Acc: {test_acc:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T14:12:39.678666Z","iopub.execute_input":"2025-06-10T14:12:39.678978Z","iopub.status.idle":"2025-06-10T14:12:39.903062Z","shell.execute_reply.started":"2025-06-10T14:12:39.678957Z","shell.execute_reply":"2025-06-10T14:12:39.902157Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1660800342.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  X_train = torch.tensor(X_train, dtype=torch.float32)\n/tmp/ipykernel_35/1660800342.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y_train = torch.tensor(y_train, dtype=torch.long)  # Targets must be long integers\n/tmp/ipykernel_35/1660800342.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  X_test = torch.tensor(X_test, dtype=torch.float32)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/100 | Train Loss: 0.7909 | Train Acc: 70.83% | Test Loss: 0.7324 | Test Acc: 73.33%\nEpoch 20/100 | Train Loss: 0.4289 | Train Acc: 95.83% | Test Loss: 0.4022 | Test Acc: 100.00%\nEpoch 30/100 | Train Loss: 0.2323 | Train Acc: 97.50% | Test Loss: 0.2255 | Test Acc: 100.00%\nEpoch 40/100 | Train Loss: 0.1127 | Train Acc: 98.33% | Test Loss: 0.1229 | Test Acc: 100.00%\nEpoch 50/100 | Train Loss: 0.0759 | Train Acc: 98.33% | Test Loss: 0.0800 | Test Acc: 100.00%\nEpoch 60/100 | Train Loss: 0.0655 | Train Acc: 98.33% | Test Loss: 0.0624 | Test Acc: 100.00%\nEpoch 70/100 | Train Loss: 0.0617 | Train Acc: 98.33% | Test Loss: 0.0546 | Test Acc: 100.00%\nEpoch 80/100 | Train Loss: 0.0597 | Train Acc: 98.33% | Test Loss: 0.0501 | Test Acc: 100.00%\nEpoch 90/100 | Train Loss: 0.0583 | Train Acc: 98.33% | Test Loss: 0.0461 | Test Acc: 100.00%\nEpoch 100/100 | Train Loss: 0.0572 | Train Acc: 97.50% | Test Loss: 0.0430 | Test Acc: 100.00%\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"test_logits = model_0(X_test)\ntrain_pred = torch.argmax(test_logits, dim=1)\ntrain_pred ,y_test\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T14:39:50.181644Z","iopub.execute_input":"2025-06-10T14:39:50.181950Z","iopub.status.idle":"2025-06-10T14:39:50.193360Z","shell.execute_reply.started":"2025-06-10T14:39:50.181927Z","shell.execute_reply":"2025-06-10T14:39:50.191659Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"(tensor([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2,\n         2, 2, 2, 2, 0, 0]),\n tensor([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2,\n         2, 2, 2, 2, 0, 0]))"},"metadata":{}}],"execution_count":77},{"cell_type":"markdown","source":"***Save model***\n","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\n\n# Create models directory (if it doesn't already exist), see: https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir\nMODEL_PATH = Path(\"models\")\nMODEL_PATH.mkdir(parents=True, # create parent directories if needed\n                 exist_ok=True # if models directory already exists, don't error\n)\n\n# Create model save path\nMODEL_NAME = \"03_pytorch_classification_model_2.pth\"\nMODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n\n# Save the model state dict\nprint(f\"Saving model to: {MODEL_SAVE_PATH}\")\ntorch.save(obj=model_0.state_dict(), # only saving the state_dict() only saves the learned parameters\n           f=MODEL_SAVE_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T14:50:43.405597Z","iopub.execute_input":"2025-06-10T14:50:43.406378Z","iopub.status.idle":"2025-06-10T14:50:43.417083Z","shell.execute_reply.started":"2025-06-10T14:50:43.406352Z","shell.execute_reply":"2025-06-10T14:50:43.416225Z"}},"outputs":[{"name":"stdout","text":"Saving model to: models/03_pytorch_classification_model_2.pth\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"***Load saved model***","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nclass LoadIrisv1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Linear(4, 10)\n        self.layer2 = nn.Linear(10, 20)\n        self.layer3 = nn.Linear(20, 3)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        x = self.relu(self.layer1(x))\n        x = self.relu(self.layer2(x))\n        x = self.layer3(x)\n        return x\n\n# 2. Create an instance of your model\nmodel = LoadIrisv1()\n\n# 3. Load the saved state dictionary\nmodel_path = \"models/03_pytorch_classification_model_2.pth\"\nmodel.load_state_dict(torch.load(model_path))\n\n# 4. Set to evaluation mode\nmodel.eval()\n\n# Now your model is ready for inference!\n\ntorch.argmax(model(X_test),dim=1),y_test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T14:59:17.033058Z","iopub.execute_input":"2025-06-10T14:59:17.033322Z","iopub.status.idle":"2025-06-10T14:59:17.046055Z","shell.execute_reply.started":"2025-06-10T14:59:17.033304Z","shell.execute_reply":"2025-06-10T14:59:17.045286Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"(tensor([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2,\n         2, 2, 2, 2, 0, 0]),\n tensor([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2,\n         2, 2, 2, 2, 0, 0]))"},"metadata":{}}],"execution_count":84}]}