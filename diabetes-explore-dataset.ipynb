{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.datasets import load_diabetes\n\ndata=load_diabetes()\ndir(data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T16:14:46.007792Z","iopub.execute_input":"2025-06-09T16:14:46.008374Z","iopub.status.idle":"2025-06-09T16:14:46.025961Z","shell.execute_reply.started":"2025-06-09T16:14:46.008346Z","shell.execute_reply":"2025-06-09T16:14:46.025089Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['DESCR',\n 'data',\n 'data_filename',\n 'data_module',\n 'feature_names',\n 'frame',\n 'target',\n 'target_filename']"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"\ndata.target\n\nX=data.data\ny=data.target\ndata.feature_names\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T17:41:37.498660Z","iopub.execute_input":"2025-06-09T17:41:37.499185Z","iopub.status.idle":"2025-06-09T17:41:37.505466Z","shell.execute_reply.started":"2025-06-09T17:41:37.499160Z","shell.execute_reply":"2025-06-09T17:41:37.504512Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T16:17:13.773977Z","iopub.execute_input":"2025-06-09T16:17:13.774318Z","iopub.status.idle":"2025-06-09T16:17:13.779859Z","shell.execute_reply.started":"2025-06-09T16:17:13.774296Z","shell.execute_reply":"2025-06-09T16:17:13.778959Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch\nfrom sklearn.preprocessing import StandardScaler\n\n# If your data is already a numpy array (common if loaded from sklearn dataset):\n# X_train and y_train are numpy arrays (no need to call .numpy())\n\n# Standard scaling for X\nscaler_X = StandardScaler()\nX_train_scaled = scaler_X.fit_transform(X_train)  # no .numpy()\nX_test_scaled = scaler_X.transform(X_test)\n\n# Standard scaling for y\nscaler_y = StandardScaler()\ny_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).squeeze()\ny_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).squeeze()\n\n# Convert to torch tensors\nX_train = torch.from_numpy(X_train_scaled).float()\nX_test = torch.from_numpy(X_test_scaled).float()\ny_train = torch.from_numpy(y_train_scaled).float()\ny_test = torch.from_numpy(y_test_scaled).float()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T17:53:48.249170Z","iopub.execute_input":"2025-06-09T17:53:48.249513Z","iopub.status.idle":"2025-06-09T17:53:48.258923Z","shell.execute_reply.started":"2025-06-09T17:53:48.249491Z","shell.execute_reply":"2025-06-09T17:53:48.258088Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"len(X_train),len(X_test),len(y_train),len(y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T17:45:26.263719Z","iopub.execute_input":"2025-06-09T17:45:26.264031Z","iopub.status.idle":"2025-06-09T17:45:26.270184Z","shell.execute_reply.started":"2025-06-09T17:45:26.264009Z","shell.execute_reply":"2025-06-09T17:45:26.269433Z"}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"(353, 89, 353, 89)"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"X_train.shape\n\nX_train=torch.tensor(X_train, dtype=torch.float32)\nX_test=torch.tensor(X_test, dtype=torch.float32)\ny_train=torch.tensor(y_train, dtype=torch.float32)\ny_test=torch.tensor(y_test, dtype=torch.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T17:45:29.285514Z","iopub.execute_input":"2025-06-09T17:45:29.285838Z","iopub.status.idle":"2025-06-09T17:45:29.292990Z","shell.execute_reply.started":"2025-06-09T17:45:29.285817Z","shell.execute_reply":"2025-06-09T17:45:29.292099Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1130877505.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y_train=torch.tensor(y_train, dtype=torch.float32)\n/tmp/ipykernel_35/1130877505.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y_test=torch.tensor(y_test, dtype=torch.float32)\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"# y=weight*x.T+ bias this is wrong\n\n# y= x * weight.T + bias\n\n\nimport torch\ntorch.manual_seed(42)\nn_in, n_out = 10, 1\nlimit = (6 / (n_in + n_out)) ** 0.5\nweight = torch.empty(n_out, n_in).uniform_(-limit, limit)\nbias = torch.zeros(n_out)\n\nweight=weight.T\nweight.shape\n\nbias\n\nweight1=torch.empty(n_in,n_out).uniform_(-limit,limit)\nweight1.shape\nweight.shape\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T16:49:34.481975Z","iopub.execute_input":"2025-06-09T16:49:34.482822Z","iopub.status.idle":"2025-06-09T16:49:34.492054Z","shell.execute_reply.started":"2025-06-09T16:49:34.482794Z","shell.execute_reply":"2025-06-09T16:49:34.491093Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"torch.Size([10, 1])"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T17:06:45.405636Z","iopub.execute_input":"2025-06-09T17:06:45.405923Z","iopub.status.idle":"2025-06-09T17:06:45.410229Z","shell.execute_reply.started":"2025-06-09T17:06:45.405903Z","shell.execute_reply":"2025-06-09T17:06:45.409339Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super().__init__()  # Corrected here!\n\n        n_in, n_out = 10, 1\n        limit = (6 / (n_in + n_out)) ** 0.5\n\n        # Xavier initialization for weight\n        self.weight = nn.Parameter(torch.empty(n_in, n_out).uniform_(-limit, limit))\n\n        # Bias initialized to zeros\n        self.bias = nn.Parameter(torch.zeros(n_out))\n\n    def forward(self, x):\n        # Use matrix multiplication (equivalent to x @ weight)\n        return x @ self.weight + self.bias\n\nmodel_0 = LinearRegression()\nprint(model_0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T17:19:33.803528Z","iopub.execute_input":"2025-06-09T17:19:33.803834Z","iopub.status.idle":"2025-06-09T17:19:33.811701Z","shell.execute_reply.started":"2025-06-09T17:19:33.803813Z","shell.execute_reply":"2025-06-09T17:19:33.810890Z"}},"outputs":[{"name":"stdout","text":"LinearRegression()\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"model_0=LinearRegression()\nmodel_0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T17:19:42.632610Z","iopub.execute_input":"2025-06-09T17:19:42.633479Z","iopub.status.idle":"2025-06-09T17:19:42.638970Z","shell.execute_reply.started":"2025-06-09T17:19:42.633444Z","shell.execute_reply":"2025-06-09T17:19:42.638136Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"LinearRegression()"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"res=model_0(X_test)\nres","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T17:45:49.522227Z","iopub.execute_input":"2025-06-09T17:45:49.522572Z","iopub.status.idle":"2025-06-09T17:45:49.531703Z","shell.execute_reply.started":"2025-06-09T17:45:49.522550Z","shell.execute_reply":"2025-06-09T17:45:49.530692Z"}},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"tensor([[ 2.9932e+02],\n        [ 1.6250e+02],\n        [ 2.6287e+02],\n        [ 8.6061e+02],\n        [ 1.7334e+02],\n        [ 5.3432e+01],\n        [ 6.0804e+02],\n        [ 5.2394e+02],\n        [-1.0446e+02],\n        [ 7.6174e+01],\n        [-8.5932e+01],\n        [ 1.9056e+00],\n        [-4.0050e+02],\n        [ 5.1457e+02],\n        [-2.7425e+01],\n        [-9.2271e-01],\n        [ 5.6786e+02],\n        [ 6.7824e+02],\n        [ 1.3779e+02],\n        [ 4.8356e+02],\n        [ 2.2930e+02],\n        [-7.1777e+01],\n        [-2.3755e+02],\n        [ 3.7228e+02],\n        [ 4.2113e+01],\n        [ 2.3068e+02],\n        [ 2.9020e+02],\n        [ 2.6733e+02],\n        [-4.1448e+02],\n        [ 1.3503e+02],\n        [ 2.6604e+02],\n        [-1.3678e+02],\n        [ 1.1874e+02],\n        [ 3.4559e+02],\n        [ 3.3550e+02],\n        [ 3.7717e+02],\n        [ 1.0358e+02],\n        [ 1.7106e+02],\n        [ 3.3699e+02],\n        [-3.0617e+02],\n        [-1.6037e+02],\n        [ 6.5858e+00],\n        [ 1.2302e+02],\n        [ 3.2726e+02],\n        [ 2.3730e+02],\n        [-2.6652e+02],\n        [-2.5363e+02],\n        [-2.0675e+02],\n        [-3.3741e+02],\n        [ 4.8408e+01],\n        [-7.3315e+01],\n        [-3.2545e+02],\n        [ 9.4655e+01],\n        [-8.2414e+01],\n        [ 4.3221e+02],\n        [-2.8516e+00],\n        [-3.6588e+01],\n        [ 3.1150e+02],\n        [-1.0391e+02],\n        [-3.6793e+02],\n        [ 3.9634e+02],\n        [ 2.0992e+02],\n        [-1.2794e-01],\n        [ 3.8424e+01],\n        [ 4.7890e+01],\n        [ 3.5053e+02],\n        [ 3.7549e+02],\n        [ 2.1070e+02],\n        [-2.3437e+02],\n        [ 1.2339e+02],\n        [ 2.5565e+02],\n        [ 4.7929e+02],\n        [ 6.6322e+02],\n        [ 7.2150e+01],\n        [-2.1638e+02],\n        [ 3.2685e+02],\n        [ 5.0526e+02],\n        [ 3.0244e+02],\n        [ 2.6619e+02],\n        [ 3.7714e+02],\n        [-8.5916e+01],\n        [-1.2957e+02],\n        [-3.4159e+02],\n        [-2.3288e+02],\n        [-6.2963e+01],\n        [-2.3104e+02],\n        [-4.0307e+02],\n        [-3.5528e+02],\n        [ 3.4617e+01]], grad_fn=<AddBackward0>)"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"loss_fn=nn.MSELoss()\n\noptimizer=torch.optim.SGD(params=model_0.parameters(),lr=0.01)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T17:59:06.815649Z","iopub.execute_input":"2025-06-09T17:59:06.816611Z","iopub.status.idle":"2025-06-09T17:59:06.820923Z","shell.execute_reply.started":"2025-06-09T17:59:06.816579Z","shell.execute_reply":"2025-06-09T17:59:06.820086Z"}},"outputs":[],"execution_count":103},{"cell_type":"code","source":"# Calculate accuracy (a classification metric)\ndef accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n    acc = (correct / len(y_pred)) * 100 \n    return acc\ndef r2_score(y_true, y_pred):\n    y_true_mean = torch.mean(y_true)\n    ss_tot = torch.sum((y_true - y_true_mean) ** 2)\n    ss_res = torch.sum((y_true - y_pred) ** 2)\n    r2 = 1 - ss_res / ss_tot\n    return r2.item()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T17:56:14.062356Z","iopub.execute_input":"2025-06-09T17:56:14.062716Z","iopub.status.idle":"2025-06-09T17:56:14.068656Z","shell.execute_reply.started":"2025-06-09T17:56:14.062691Z","shell.execute_reply":"2025-06-09T17:56:14.067566Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"\n\nepochs=10000\n\nfor i in range(epochs):\n    model_0.train()\n    y_pred=model_0(X_train).squeeze()\n    loss=loss_fn(y_pred,y_train)\n    acc=r2_score(y_train,y_pred)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    model_0.eval()\n    with torch.inference_mode():\n        y_pred1=model_0(X_test).squeeze()\n        loss1=loss_fn(y_pred1,y_test)\n        acc1=r2_score(y_test,y_pred1)\n\n    if i%2000==0:\n        print(f\"Train loss -> {loss.item()} | test loss -> {loss1.item()} | train acc-> {acc} | test acc -> {acc1}\")\n        \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T17:59:12.994144Z","iopub.execute_input":"2025-06-09T17:59:12.994509Z","iopub.status.idle":"2025-06-09T17:59:19.617568Z","shell.execute_reply.started":"2025-06-09T17:59:12.994485Z","shell.execute_reply":"2025-06-09T17:59:19.616785Z"}},"outputs":[{"name":"stdout","text":"Train loss -> 0.47208064794540405 | test loss -> 0.47728845477104187 | train acc-> 0.527919352054596 | test acc -> 0.4526025652885437\nTrain loss -> 0.47208064794540405 | test loss -> 0.47728845477104187 | train acc-> 0.527919352054596 | test acc -> 0.4526025652885437\nTrain loss -> 0.47208064794540405 | test loss -> 0.47728845477104187 | train acc-> 0.527919352054596 | test acc -> 0.4526025652885437\nTrain loss -> 0.47208064794540405 | test loss -> 0.47728845477104187 | train acc-> 0.527919352054596 | test acc -> 0.4526025652885437\nTrain loss -> 0.47208064794540405 | test loss -> 0.47728845477104187 | train acc-> 0.527919352054596 | test acc -> 0.4526025652885437\n","output_type":"stream"}],"execution_count":104},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(10, 1)\n\n    def forward(self, x):\n        return self.linear(x).squeeze()  # squeeze for shape\n\nmodel_0 = LinearRegression()\nprint(model_0)\n\nloss_fn = nn.MSELoss()\noptimizer = torch.optim.SGD(model_0.parameters(), lr=0.01)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T18:03:44.673659Z","iopub.execute_input":"2025-06-09T18:03:44.673971Z","iopub.status.idle":"2025-06-09T18:03:51.707140Z","shell.execute_reply.started":"2025-06-09T18:03:44.673948Z","shell.execute_reply":"2025-06-09T18:03:51.706078Z"}},"outputs":[{"name":"stdout","text":"LinearRegression(\n  (linear): Linear(in_features=10, out_features=1, bias=True)\n)\nTrain loss -> 2.0573 | test loss -> 1.4481 | train R2-> -1.0573 | test R2 -> -0.6608\nTrain loss -> 0.4735 | test loss -> 0.4756 | train R2-> 0.5265 | test R2 -> 0.4545\nTrain loss -> 0.4728 | test loss -> 0.4757 | train R2-> 0.5272 | test R2 -> 0.4544\nTrain loss -> 0.4724 | test loss -> 0.4761 | train R2-> 0.5276 | test R2 -> 0.4540\nTrain loss -> 0.4722 | test loss -> 0.4764 | train R2-> 0.5278 | test R2 -> 0.4536\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"epochs = 10000\n\nfor i in range(epochs):\n    model_0.train()\n    y_pred = model_0(X_train)\n    loss = loss_fn(y_pred, y_train)\n    acc = r2_score(y_train, y_pred)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    model_0.eval()\n    with torch.inference_mode():\n        y_pred1 = model_0(X_test)\n        loss1 = loss_fn(y_pred1, y_test)\n        acc1 = r2_score(y_test, y_pred1)\n\n    if i % 2000 == 0:\n        print(f\"Train loss -> {loss.item():.4f} | test loss -> {loss1.item():.4f} | train R2-> {acc:.4f} | test R2 -> {acc1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T18:05:16.808872Z","iopub.execute_input":"2025-06-09T18:05:16.809156Z","iopub.status.idle":"2025-06-09T18:05:23.862275Z","shell.execute_reply.started":"2025-06-09T18:05:16.809135Z","shell.execute_reply":"2025-06-09T18:05:23.861498Z"}},"outputs":[{"name":"stdout","text":"Train loss -> 0.4721 | test loss -> 0.4773 | train R2-> 0.5279 | test R2 -> 0.4526\nTrain loss -> 0.4721 | test loss -> 0.4773 | train R2-> 0.5279 | test R2 -> 0.4526\nTrain loss -> 0.4721 | test loss -> 0.4773 | train R2-> 0.5279 | test R2 -> 0.4526\nTrain loss -> 0.4721 | test loss -> 0.4773 | train R2-> 0.5279 | test R2 -> 0.4526\nTrain loss -> 0.4721 | test loss -> 0.4773 | train R2-> 0.5279 | test R2 -> 0.4526\n","output_type":"stream"}],"execution_count":110}]}